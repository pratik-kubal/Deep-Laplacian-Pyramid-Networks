{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Conv2D, LeakyReLU, UpSampling2D, Conv2DTranspose, Add, ReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 64\n",
    "D = 5\n",
    "R = 8\n",
    "kernel = (3,3)\n",
    "def build_conv(D,filters,kernel):\n",
    "    _in = Input((None,None,64))\n",
    "    x = Conv2D(filters, kernel,\n",
    "               padding='same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               name='conv1',\n",
    "               use_bias=False)(_in)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    for idx in range(D-1):\n",
    "        x = Conv2D(filters, kernel,\n",
    "                   padding='same',\n",
    "                   kernel_initializer = 'he_normal',\n",
    "                   name='conv'+str(idx+2),\n",
    "                   use_bias=False)(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    return Model(_in,x)\n",
    "conv = build_conv(D,filters,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_embedding(shared_conv):\n",
    "    _in = Input((None,None,64))\n",
    "    # Conv1\n",
    "    x = shared_conv(_in)\n",
    "    return Model(_in,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_init(shape):\n",
    "    # https://github.com/tensorlayer/tensorlayer/issues/53\n",
    "    num_channels = shape[3]\n",
    "    bilinear_kernel = np.zeros([shape[0], shape[1]], dtype=np.float32)\n",
    "    scale_factor = (shape[0] + 1) // 2\n",
    "    if shape[1] % 2 == 1:\n",
    "        center = scale_factor - 1\n",
    "    else:\n",
    "        center = scale_factor - 0.5\n",
    "    for x in range(shape[0]):\n",
    "        for y in range(shape[1]):\n",
    "            bilinear_kernel[x,y] = (1 - abs(x - center) / scale_factor) * (1 - abs(y - center) / scale_factor)\n",
    "    weights = np.zeros((shape[0], shape[1], num_channels, num_channels))\n",
    "    for i in range(num_channels):\n",
    "        weights[:, :, i, i] = bilinear_kernel\n",
    "    return K.variable(weights)\n",
    "\n",
    "def feature_upsampling(): \n",
    "    _in = Input((None,None,64))\n",
    "    x = Conv2DTranspose(64,(4,4),\n",
    "                        strides=2,\n",
    "                        padding='same',\n",
    "                        kernel_initializer = bilinear_init,\n",
    "                        use_bias=False,\n",
    "                        name='feat_up')(_in)\n",
    "    return Model(_in,x)\n",
    "\n",
    "def image_upsampling():\n",
    "    _in = Input((None,None,3))\n",
    "    x = Conv2DTranspose(3,(4,4),\n",
    "                        strides=2,\n",
    "                        padding='same',\n",
    "                        kernel_initializer = bilinear_init,\n",
    "                        use_bias=False,\n",
    "                        name='img_up')(_in)\n",
    "    return Model(_in,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_res(R,shared_conv):\n",
    "    \n",
    "    _in = Input((None,None,64))\n",
    "    \n",
    "    x = shared_conv(_in)\n",
    "    for idx in range(R-1):\n",
    "        x = shared_conv(x)\n",
    "    \n",
    "    x = Conv2D(3,(3,3),\n",
    "               strides=1,\n",
    "               padding='same',\n",
    "               activation='sigmoid',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               name='sub_band1',\n",
    "               use_bias=False)(x)\n",
    "    \n",
    "    return Model(_in,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_feat_emb = feature_embedding(conv)\n",
    "shared_feat_up = feature_upsampling()\n",
    "shared_conv_res = conv_res(R,conv)\n",
    "shared_img_up = image_upsampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_feat_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "184+65+65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LapSRN():\n",
    "    shared_conv = build_conv(D,filters,kernel)\n",
    "    shared_feat_emb = feature_embedding(shared_conv)\n",
    "    shared_feat_up = feature_upsampling()\n",
    "    shared_conv_res = conv_res(8,shared_conv)\n",
    "    shared_img_up = image_upsampling()\n",
    "    _in = Input((64,64,3))\n",
    "    x = Conv2D(64,(3,3),strides=1,padding='same',name='conv_in',kernel_initializer = 'he_normal')(_in)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    feat_emb_2x = shared_feat_emb(x)\n",
    "    feat_up_2x = shared_feat_up(feat_emb_2x)\n",
    "    sub_band_res_2x = shared_conv_res(feat_up_2x)\n",
    "    img_up_2x = shared_img_up(_in)\n",
    "    hr_2x_out = Add()([sub_band_res_2x,img_up_2x])\n",
    "    \n",
    "    \n",
    "    feat_emb_4x = shared_feat_emb(feat_up_2x)\n",
    "    feat_up_4x = shared_feat_up(feat_emb_4x)\n",
    "    sub_band_res_4x = shared_conv_res(feat_up_4x)\n",
    "    img_up_4x = shared_img_up(hr_2x_out)\n",
    "    hr_4x_out = Add()([sub_band_res_4x,img_up_4x])\n",
    "    \n",
    "    return Model(_in,[hr_2x_out,hr_4x_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    '''\n",
    "    y_true -> Is the array of bicubic downsampled HR images at each level\n",
    "    y_pred -> Is the addition of sub band residuals from conv_res and upsampling ie img_up\n",
    "    '''\n",
    "    r = y_true - y_pred\n",
    "    # Charbonnier penalty\n",
    "    epsilon = 1e-3\n",
    "    p = K.sqrt(K.square(r) + K.square(epsilon))\n",
    "    return K.mean(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LapSRN = build_LapSRN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LapSRN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "253-222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LapSRN.compile(loss=loss_function, optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "envPath = '../'\n",
    "import sys\n",
    "sys.path.append(envPath+'model/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from LapSRN import LapSRN as network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LapSRN = network(optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1204 21:36:58.077900 139780360537920 deprecation_wrapper.py:119] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1204 21:36:58.080211 139780360537920 deprecation_wrapper.py:119] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1204 21:36:58.088945 139780360537920 deprecation_wrapper.py:119] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1204 21:36:58.142784 139780360537920 deprecation.py:323] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:2618: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1204 21:36:58.451879 139780360537920 deprecation_wrapper.py:119] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LapSRN_model = LapSRN.get_LapSRN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_in (Conv2D)                (None, 64, 64, 64)   1792        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 64)   0           conv_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             184640      leaky_re_lu_6[0][0]              \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 multiple             65536       model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 multiple             186371      model_3[1][0]                    \n",
      "                                                                 model_3[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 multiple             144         input_6[0][0]                    \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 3)  0           model_4[1][0]                    \n",
      "                                                                 model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 3)  0           model_4[2][0]                    \n",
      "                                                                 model_5[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 253,843\n",
      "Trainable params: 253,843\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LapSRN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
