{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Conv2D, LeakyReLU, UpSampling2D, Conv2DTranspose, Add, ReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_embedding():\n",
    "    _in = Input((None,None,64))\n",
    "    # Conv1\n",
    "    x = Conv2D(64, (3, 3),\n",
    "               activation='relu',\n",
    "               padding='same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               name='feat_emb1')(_in)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # Conv2\n",
    "    x = Conv2D(64, (3, 3),\n",
    "               padding='same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               name='feat_emb2')(_in)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # Conv3\n",
    "    x = Conv2D(64, (3, 3),\n",
    "               padding='same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               name='feat_emb3')(_in)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # Conv4\n",
    "    x = Conv2D(64, (3, 3),\n",
    "               padding='same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               name='feat_emb4')(_in)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # Conv5\n",
    "    x = Conv2D(64, (3, 3),\n",
    "               padding='same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               name='feat_emb5')(_in)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return Model(_in,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_init(shape):\n",
    "    # https://github.com/tensorlayer/tensorlayer/issues/53\n",
    "    num_channels = shape[3]\n",
    "    bilinear_kernel = np.zeros([shape[1], shape[2]], dtype=np.float32)\n",
    "    scale_factor = (shape[1] + 1) // 2\n",
    "    if shape[1] % 2 == 1:\n",
    "        center = scale_factor - 1\n",
    "    else:\n",
    "        center = scale_factor - 0.5\n",
    "    for x in range(shape[1]):\n",
    "        for y in range(shape[1]):\n",
    "            bilinear_kernel[x,y] = (1 - abs(x - center) / scale_factor) * \\\n",
    "                                   (1 - abs(y - center) / scale_factor)\n",
    "    weights = np.zeros((shape[1], shape[2], num_channels, num_channels))\n",
    "    for i in range(num_channels):\n",
    "        weights[:, :, i, i] = bilinear_kernel\n",
    "    return K.variable(weights)\n",
    "\n",
    "def feature_upsampling(): \n",
    "    _in = Input((None,None,64))\n",
    "    x = Conv2DTranspose(64,(3,3),\n",
    "                        strides=2,\n",
    "                        padding='same',\n",
    "                        kernel_initializer = bilinear_init,\n",
    "                        name='feat_up')(_in)\n",
    "    return Model(_in,x)\n",
    "\n",
    "def image_upsampling():\n",
    "    _in = Input((None,None,3))\n",
    "    x = Conv2DTranspose(3,(3,3),\n",
    "                        strides=2,\n",
    "                        padding='same',\n",
    "                        kernel_initializer = bilinear_init,\n",
    "                        name='img_up')(_in)\n",
    "    return Model(_in,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_res():\n",
    "    def residual_block(_input,skip_conn,num):\n",
    "        # Conv 1\n",
    "        a = ReLU()(_input)\n",
    "        a = Conv2D(64, (3, 3),\n",
    "                   padding='same',\n",
    "                   kernel_initializer = 'he_normal',\n",
    "                   name='conv_res1'+str(num))(a)\n",
    "        # Conv 2\n",
    "        a = ReLU()(a)\n",
    "        a = Conv2D(64, (3, 3),\n",
    "                   padding='same',\n",
    "                   kernel_initializer = 'he_normal',\n",
    "                   name='conv_res2'+str(num))(a)\n",
    "        # Conv 3\n",
    "        a = ReLU()(a)\n",
    "        a = Conv2D(64, (3, 3),\n",
    "                   padding='same',\n",
    "                   kernel_initializer = 'he_normal',\n",
    "                   name='conv_res3'+str(num))(a)\n",
    "        # Conv 4\n",
    "        a = ReLU()(a)\n",
    "        a = Conv2D(64, (3, 3),\n",
    "                   padding='same',\n",
    "                   kernel_initializer = 'he_normal',\n",
    "                   name='conv_res4'+str(num))(a)\n",
    "        # Conv 5\n",
    "        a = ReLU()(a)\n",
    "        a = Conv2D(64, (3, 3),\n",
    "                   padding='same',\n",
    "                   kernel_initializer = 'he_normal',\n",
    "                   name='conv_res5'+str(num))(a)\n",
    "        a = Add(name='res_add'+str(num))([a,skip_conn])\n",
    "        return a\n",
    "    \n",
    "    residual_blocks = 8\n",
    "    \n",
    "    _in = Input((None,None,64))\n",
    "    x = residual_block(_in,skip_conn = _in,num = 1)\n",
    "    for idx in range(residual_blocks-1):\n",
    "        x = residual_block(x,skip_conn = _in,num = idx+2)\n",
    "    \n",
    "    x = Conv2D(3,(3,3),\n",
    "               strides=1,\n",
    "               padding='same',\n",
    "               activation='sigmoid',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               name='sub_band1')(x)\n",
    "    \n",
    "    return Model(_in,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1203 07:27:11.754057 140042967582528 deprecation_wrapper.py:119] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1203 07:27:11.755717 140042967582528 deprecation_wrapper.py:119] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1203 07:27:11.759421 140042967582528 deprecation_wrapper.py:119] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1203 07:27:11.821462 140042967582528 deprecation.py:323] From /home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:2618: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    }
   ],
   "source": [
    "shared_feat_emb = feature_embedding()\n",
    "shared_feat_up = feature_upsampling()\n",
    "shared_conv_res = conv_res()\n",
    "shared_img_up = image_upsampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "img_up (Conv2DTranspose)     (None, None, None, 3)     84        \n",
      "=================================================================\n",
      "Total params: 84\n",
      "Trainable params: 84\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shared_img_up.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LapSRN():\n",
    "    shared_feat_emb = feature_embedding()\n",
    "    shared_feat_up = feature_upsampling()\n",
    "    shared_conv_res = conv_res()\n",
    "    shared_img_up = image_upsampling()\n",
    "    _in = Input((64,64,3))\n",
    "    x = Conv2D(64,(3,3),strides=1,padding='same',name='conv_in',kernel_initializer = 'he_normal')(_in)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    feat_emb_2x = shared_feat_emb(x)\n",
    "    feat_up_2x = shared_feat_up(feat_emb_2x)\n",
    "    sub_band_res_2x = shared_conv_res(feat_up_2x)\n",
    "    img_up_2x = shared_img_up(_in)\n",
    "    hr_2x_out = Add()([sub_band_res_2x,img_up_2x])\n",
    "    \n",
    "    \n",
    "    feat_emb_4x = shared_feat_emb(feat_up_2x)\n",
    "    feat_up_4x = shared_feat_up(feat_emb_4x)\n",
    "    sub_band_res_4x = shared_conv_res(feat_up_4x)\n",
    "    img_up_4x = shared_img_up(hr_2x_out)\n",
    "    hr_4x_out = Add()([sub_band_res_4x,img_up_4x])\n",
    "    \n",
    "    return Model(_in,[hr_2x_out,hr_4x_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    '''\n",
    "    y_true -> Is the array of bicubic downsampled HR images at each level\n",
    "    y_pred -> Is the addition of sub band residuals from conv_res and upsampling ie img_up\n",
    "    '''\n",
    "    r = y_true - y_pred\n",
    "    # Charbonnier penalty\n",
    "    epsilon = 1e-3\n",
    "    p = K.sqrt(K.square(r) + K.square(epsilon))\n",
    "    return K.mean(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LapSRN = build_LapSRN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_in (Conv2D)                (None, 64, 64, 64)   1792        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 64)   0           conv_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 multiple             36928       leaky_re_lu_6[0][0]              \n",
      "                                                                 model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             786496      model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 multiple             1478851     model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 multiple             84          input_5[0][0]                    \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 3)  0           model_3[1][0]                    \n",
      "                                                                 model_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 3)  0           model_3[2][0]                    \n",
      "                                                                 model_4[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,304,151\n",
      "Trainable params: 2,304,151\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LapSRN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LapSRN.compile(loss=loss_function, optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "envPath = '../'\n",
    "import sys\n",
    "sys.path.append(envPath+'model/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/envs/srPath/lib/python3.6/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "from LapSRN import LapSRN as network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
